<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <link rel="stylesheet" href="/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet"> <style id="jtd-nav-activation"> .site-nav > ul.nav-list:first-child > li > a, .site-nav > ul.nav-list:first-child > li > ul > li:not(:nth-child(1)) > a, .site-nav > ul.nav-list:first-child > li > ul > li > ul > li a { background-image: none; } .site-nav > ul.nav-list:not(:first-child) a, .site-nav li.external a { background-image: none; } .site-nav > ul.nav-list:first-child > li:nth-child(3) > ul > li:nth-child(1) > a { font-weight: 600; text-decoration: none; }.site-nav > ul.nav-list:first-child > li:nth-child(3) > button svg, .site-nav > ul.nav-list:first-child > li:nth-child(3) > ul > li:nth-child(1) > button svg { transform: rotate(-90deg); }.site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(3) > ul.nav-list, .site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(3) > ul.nav-list > li.nav-list-item:nth-child(1) > ul.nav-list { display: block; } </style> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>FinBERT 2 - Model Building | Cristian Compean</title> <meta name="generator" content="Jekyll v3.10.0" /> <meta property="og:title" content="FinBERT 2 - Model Building" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Portfolio website for Cristian Compean" /> <meta property="og:description" content="Portfolio website for Cristian Compean" /> <link rel="canonical" href="http://localhost:4000/docs/Portfolio/FinBERT_2/model_building" /> <meta property="og:url" content="http://localhost:4000/docs/Portfolio/FinBERT_2/model_building" /> <meta property="og:site_name" content="Cristian Compean" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="FinBERT 2 - Model Building" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"Portfolio website for Cristian Compean","headline":"FinBERT 2 - Model Building","url":"http://localhost:4000/docs/Portfolio/FinBERT_2/model_building"}</script> <!-- End Jekyll SEO tag --> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"> Cristian Compean </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Sampling category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/docs/Blog/Sampling/2025/05/28/sampling" class="nav-list-link">Sampling</a><ul class="nav-list"><li class="nav-list-item"><a href="/docs/Blog/Sampling/2025/05/19/rejection-sampling" class="nav-list-link">Rejection Sampling</a></li><li class="nav-list-item"><a href="/docs/Blog/Sampling/2025/05/18/Metropolis-Hastings" class="nav-list-link">Metropolis-Hastings Algorithm</a></li><li class="nav-list-item"><a href="/docs/Blog/Sampling/2025/05/27/overlap" class="nav-list-link">Overlap Measure</a></li></ul></li><li class="nav-list-item"><a href="/docs/Portfolio/Overlap_RANDHIE" class="nav-list-link">Application - Overlap Measure and RAND HIE (WIP)</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in FinBERT 2 category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/docs/Portfolio/FinBERT_2" class="nav-list-link">FinBERT 2</a><ul class="nav-list"><li class="nav-list-item"><a href="/docs/Portfolio/FinBERT_2/model_building" class="nav-list-link">FinBERT 2 - Model Building</a></li></ul></li><li class="nav-list-item"><a href="/Portfolio/2025/06/10/portfolio-website-blog" class="nav-list-link">Portfolio Website Updates</a></li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Cristian Compean" aria-label="Search Cristian Compean" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> </div> <div class="main-content-wrap"> <nav aria-label="Breadcrumb" class="breadcrumb-nav"> <ol class="breadcrumb-nav-list"> <li class="breadcrumb-nav-list-item"><a href="/docs/Portfolio/FinBERT_2">FinBERT 2</a></li> <li class="breadcrumb-nav-list-item"><span>FinBERT 2 - Model Building</span></li> </ol> </nav> <div id="main-content" class="main-content"> <main> <h1 id="introduction-to-sentiment-analysis"> <a href="#introduction-to-sentiment-analysis" class="anchor-heading" aria-labelledby="introduction-to-sentiment-analysis"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Introduction to Sentiment Analysis </h1> <p>Sentiment analysis is the popular classification technique of determining attidues around a subject, entity, or event from natural language. The method and techniques of implementing sentiment analysis are long and well-documented from “simple” and inuitive models such as logistic regression and Naive Bayes Classifier and training models using a collection of vocabulary words (Bag of Words) to highly sophisticated and state of the art large language/reasoning models such as GPT-4, o4, BERT, Claude Opus 4 trained on large corpus of text throught the use of embeding layers that preserve word order, sentiment analysis seems to be a persistent and well researched topic surrounding these forementioned methods of prediction.</p> <h3 id="sentiment-analysis-using-bert"> <a href="#sentiment-analysis-using-bert" class="anchor-heading" aria-labelledby="sentiment-analysis-using-bert"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Sentiment Analysis Using BERT </h3> <p>Improvements in the sophistication of models with the rise of attention based architecture have significantly improved performance of sentiment analysis over previous models such as recurrent neural networks or convolution neural networks due to the positional embeddings the model learns through pre-training and transformers ability to process whole sentences rather than word for word. The downside to the transformer model is its use of massive datasets and heavy computation costs. However, we overcome the limitation of pretraining BERT on the standard Wikipedia and Book corpora by using the pretrained BERT from the Huggingface library.</p> <h3 id="further-pretraining--improved-results"> <a href="#further-pretraining--improved-results" class="anchor-heading" aria-labelledby="further-pretraining--improved-results"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Further Pretraining = Improved Results? </h3> <p>Text in financial data is notoriously tricky to detect sentiment due to the unique vocabulary and the lack of proper and labeled data make applying sentiment analysis difficult. This is where FinBERT comes in. FinBERT is a variation of BERT desinged specifically for application in the financial domain by using a method known as “further pre-training” which is training a BERT model on domain relevant corpa using the same training methods (masked language modeling and next sentence prediction) done during the training on the Wikipedia and BookCourpa corpora. The authors of FinBERT decided to use Reuters TRC2 dataset and then filtering down to financial news articles for the pretraining of BERT; the idea of the pretraining is that it allows BERT to adjust its positional embeddings before it is fine-tuned on domain-specific dataset.</p> <p>After pretraining, FinBERT was then fine-tuned on the Financial Phrasebank dataset where it proved noticeable improvements over a standard BERT, ELmO, and (I forgot the last one). The result of this further pretraining demostrated the effectiveness and possibility of making better, domain-specific models for the purpose of sentiment analysis.</p> <h1 id="why-finbert-2"> <a href="#why-finbert-2" class="anchor-heading" aria-labelledby="why-finbert-2"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Why FinBERT 2? </h1> <p>The original FinBERT model was made in 2019. Since then with a substantial rise of retail investors [link here], the COVID-19 pandemic, and the impact of Artifical Intelligence, rising interest rates have made both changes in the way we communicate and the way markets, particularly stock markets, operate in higher volatility enviroment.</p> <p>It is my personal belief that the change in enviroment should be reflected in the data we use to train our LLMs, this to me, is particularly important when it comes to training LLMs on domain specific tasks.</p> <p>For that reason, the data we collect and use to train FinBERT 2 should reflect my sentiment. Ideally, we want a LLM that is knowledgeable on financial vocabulary and news but is also an excellent room reader and can understand the anger/frustration/skepticism traders may have towards a stock.</p> <h1 id="collecting-datasets"> <a href="#collecting-datasets" class="anchor-heading" aria-labelledby="collecting-datasets"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Collecting Datasets </h1> <h2 id="model-training-and-data-colletion"> <a href="#model-training-and-data-colletion" class="anchor-heading" aria-labelledby="model-training-and-data-colletion"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Model Training and Data Colletion </h2> <p>For the pretraining, we’ll be using Huggingface extensively as it offers a variety of benefits when it comes to training LLMs. Using HuggingFace gives us access to a variety of large datasets perfect for training LLMs and are easy to access using the HuggingFace API in Python. HuggingFace also allows for me store up to 100gb that can be used to store tokenized datasets so they don’t have to be loaded in locally. Most importantly, as noted earlier, HuggingFace provides easy access to the BERT model that is already pretrained on the Wikipedia and BookCorpus corpora along with the functions necessary to carry out the further pretraining.</p> <h2 id="data-accessing"> <a href="#data-accessing" class="anchor-heading" aria-labelledby="data-accessing"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Data Accessing </h2> <p>To access the Huggingface datasets, we’ll be using PySpark over popular alternatives such as Pandas. The reason for this is that if we wanted to increase the number of datasets to manage, PySpark would easily be able to handle the processing and loading required by the data.</p> <h2 id="data-collection"> <a href="#data-collection" class="anchor-heading" aria-labelledby="data-collection"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Data Collection </h2> <p>For further pretraining, the two datasets we’ll look to use are the <a href="https://huggingface.co/datasets/danidanou/Reuters_Financial_News">Reuteurs Financial Dataset</a> that records Reuteurs Financial news artciles from 2006-2013 and this corpora of <a href="https://huggingface.co/datasets/ashraq/financial-news-articles">Financial News Articles</a> from seemingly 2017-2018. Finally, we’ll use the <a href="https://huggingface.co/datasets/StephanAkkerman/financial-tweets">FinTwit dataset</a>.</p> </main> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
