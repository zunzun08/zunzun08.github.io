{"0": {
    "doc": "Metropolis-Hastings Algorithm",
    "title": "The Metropolis-Hastings Algorithm",
    "content": " ",
    "url": "/docs/Blog/Sampling/2025/05/18/Metropolis-Hastings#the-metropolis-hastings-algorithm",
    
    "relUrl": "/docs/Blog/Sampling/2025/05/18/Metropolis-Hastings#the-metropolis-hastings-algorithm"
  },"1": {
    "doc": "Metropolis-Hastings Algorithm",
    "title": "Introduction",
    "content": "The Metropolis-Hastings (MH) algorithm is a Monte Carlo Markov Chain (MCMC) method that allows us to generate samples from a target distribution. A target distribution is a function whose form is known but whose constant of proportionality is unknown and/or cannot be calculated through traditional methods or numerical methods. Because the constant of proportionality cannot be calculated, traditional methods of sampling such as the inverse CDF method cannot be applied. We’ll assume that the rejection sampling method does not work here for our proposal and target distributions. Instead, we turn to the Metropolis Hastings algorithm which works by also works by an iterative process. The Metropolis Hastings algorithm draws samples from a proposal probability density function and based on an overlap measure, the sample is accepted or rejected. After some number of iterations, the samples accepted by the MH algorithm follow the target distribution without ever having to calculate the constant of integration. Example . Suppose $q(x) \\sim N(0,1)$ and $p(x) \\sim N(1,2)$ where $p(x)$ is a distribution that is easy to sample from and $q(x)$ is difficult to sample from. By applying the MH Algorithm 10,000 times, and only sampling from $p(x)$, we can achieve the following result: . Effectively, samples from $p(x)$ and conclude that they are accepted as approximations of $q(x)$. ",
    "url": "/docs/Blog/Sampling/2025/05/18/Metropolis-Hastings#introduction",
    
    "relUrl": "/docs/Blog/Sampling/2025/05/18/Metropolis-Hastings#introduction"
  },"2": {
    "doc": "Metropolis-Hastings Algorithm",
    "title": "Mathematical Background",
    "content": "Before formally defining the MH algorithm, I’d like to recall or introduce a few concepts that the reader should be familiar with to understand the proof of the MH algorithm. Monte Carlo . Monte Carlo methods are a class of computational techniques that use random sampling to approximate mathematical quantities, such as integrals. These methods are useful when analytical solutions are difficult or impossible to obtain. Given a probability density function $f(x)$ and independently and identically distributed (i.i.d) samples $X_1, X_2, …, X_n$ from $f(x)$, we can approximate the integral of a continuous function $a(x)$ with respect to $f(x)$: . \\[I = \\int a(x)f(x)\\text{d}x\\] With the following estimate: . \\[\\hat{I} = \\frac{1}{n} \\sum_{i=1}^{n} a(x_i)\\] Where $\\hat{I}$ is an unbiased estimator of $I$. By the law of large numbers $\\hat{I} \\rightarrow I$ and $\\text{E}[\\hat{I}] = I$ . Proof: . It should be noted that by the Law of the Unconscious Statistician: . \\[I = \\int a(x)f(x)dx = \\text{E}[a(x)]\\] By properties of expected value we apply the following: . \\[\\text{E}[\\hat{I}] = \\text{E}[\\frac{1}{n} \\sum_{i=1}^n a(x_i)] = \\frac{1}{n} \\sum_{i=1}^n \\text{E}[a(x_i)]\\] Since $X_1, X_2, …, X_n$ are i.i.d . \\[\\text{E}[\\hat{I}] = \\frac{1}{n} (nI) = I = \\text{E}[a(x)]\\] QED . We can also show that as the number of samples increase, our estimate approaches the true value. \\begin{proof} . \\[\\text{Var}[\\hat{I}] = \\text{Var}[\\frac{1}{n} \\sum_{i=1}^na(x_i)] = \\frac{1}{n^2}\\sum_i \\text{Var}[a(x_i)]\\] Since our samples are i.i.d: . \\[=\\frac{1}{n^2}(n\\text{Var}[a(x_i)]) = \\frac{1}{n}\\text{Var}[a(x_i)]\\] Now applying the limit: . \\[\\lim_{n \\rightarrow \\infty} \\frac{1}{n}\\text{Var}[a(x_i)] = 0\\] QED . ",
    "url": "/docs/Blog/Sampling/2025/05/18/Metropolis-Hastings#mathematical-background",
    
    "relUrl": "/docs/Blog/Sampling/2025/05/18/Metropolis-Hastings#mathematical-background"
  },"3": {
    "doc": "Metropolis-Hastings Algorithm",
    "title": "Markov Chain",
    "content": "A Markov chain is a stochastic process where the future state depends only on the current state and not on the sequence of events that preceded it. A key concept in Markov chains is the stationary distribution, which is a probability distribution that remains unchanged as the chain evolves over time. The MC Stationary property requires the following: . | A p.d.f: $f(x)$ | An i.i.d sample $X_1, X_2, …, X_n$ drawn from $\\Pr(\\cdot \\vert x_{i-1})$, the transition kernel from the previous state, $x_{i-1}$. | The stationary distribution must satisfy the following process: | . \\[f(y) = \\int \\Pr(y \\vert x) f(x) \\text{dx}\\] If all three conditions are met, then the following is true: . If the initial state $X_1$,​ is drawn from the stationary distribution $f(x)$, and each subsequent state $X_{i+1}$ is drawn from $\\Pr⁡(⋅\\vert x_i)$, then all states $X_i$ will also follow the stationary distribution $f(x)$. ",
    "url": "/docs/Blog/Sampling/2025/05/18/Metropolis-Hastings#markov-chain",
    
    "relUrl": "/docs/Blog/Sampling/2025/05/18/Metropolis-Hastings#markov-chain"
  },"4": {
    "doc": "Metropolis-Hastings Algorithm",
    "title": "Markov Chain Monte Carlo",
    "content": "Markov Chain Monte Carlo (MCMC) methods combine Monte Carlo sampling with Markov chains to generate samples from a target probability distribution $f(x)$. Given a sequence of samples $X_1,X_2,…,X_n$ generated by an ergodic Markov chain with stationary distribution $f(x)$, we can approximate expectations of a function $a(x)$ as follows: . \\[\\mathbb{E}_f[a(x)] \\approx \\frac{1}{n} \\sum_{i=1}^n a(x_i)\\] This approximation holds under the condition that the Markov chain will eventually produce samples that are distributed according to $f(x)$, even if the samples are not independent. By the definition above and the description above, the MH algorithm is an MCMC method. ",
    "url": "/docs/Blog/Sampling/2025/05/18/Metropolis-Hastings#markov-chain-monte-carlo",
    
    "relUrl": "/docs/Blog/Sampling/2025/05/18/Metropolis-Hastings#markov-chain-monte-carlo"
  },"5": {
    "doc": "Metropolis-Hastings Algorithm",
    "title": "Metropolis-Hastings Algorithm",
    "content": ". | Pick $p(x)$ and $q(x)$ where $p(x)$ is a distribution that can be easily sampled from. | Set an initial value of $x$ (could be anything, keep it reasonable) | Take $x'$ from $p(x)$ | Evaluate $q(x')$ | Compute $\\alpha(x', x) = \\min(1, \\frac{p(x')q(x|x')}{p(x)q(x'|x)})$ | Draw a random sample $u$ from $\\text{Uniform}[0,1]$ | Accept or reject: If $u &lt; \\alpha(x',x)$: $x_2 = x'$ ,else: $x_2 = x_1$ | . ",
    "url": "/docs/Blog/Sampling/2025/05/18/Metropolis-Hastings#metropolis-hastings-algorithm",
    
    "relUrl": "/docs/Blog/Sampling/2025/05/18/Metropolis-Hastings#metropolis-hastings-algorithm"
  },"6": {
    "doc": "Metropolis-Hastings Algorithm",
    "title": "Proof of Metropolis Hastings Algorithm",
    "content": "From the algorithm we know applying the MH Algorithm does the following: . The algorithm implies that for any $X_i$ and $X_{i+1}$ for $1 \\leq i \\leq n$ there must be a density $\\Pr(X_{i+1} \\vert X_i)$ that facilitates the movement of random variables. We also wish to prove $q(X_{i+1}) = \\int \\Pr(X_{i+1} \\vert X_{i}) q(X_{i}) dX_{i}$ which is the stationary condition for our target distribution. However, we first need to find $\\Pr(x_{n+1} \\vert x_n)$ is before we can show the stationary condition holds. Finding $\\Pr(X_{n+1} \\vert X_n)$: . $X_{n+1}$ can take on two values. Either $X_{n+1}$ takes on the values of $x’$ with some probability $w(x)$ or the sample is rejected in which case $X_{n+1} = x_n$. We can represent this as: . \\[X_{n+1} = \\begin{cases} x' \\text{ determined by w(x)} \\\\ x_n \\text{ 1- w(x)} \\end{cases}\\] Since we are looking to determine $\\Pr(X_{n+1} \\vert X_n)$, using the Law of Total Probability, we get: . \\[\\Pr(X_{n+1} | X_n) = \\text{Pr}(X_{n+1} = x' | X_{n} = x_{n} ) + (1- \\text{Pr}(X_{n+1} = x' | X_{n} = x_{n} )) \\cdot 1(X_{n+1} = X_n)\\] Where $1(X_{n+1} = X_n)$ is an indicator variable that tells us our sample was rejected. Let’s take $\\Pr(X_{n+1} = x’ \\vert X_{n} = x_n)$, the probability we move from one state to the next apart and quantify the result. \\[\\Pr(X_{n+1} = x' | X_{n} = x_n) = \\Pr(X' | X_n = x_n) \\cdot \\Pr(U \\leq \\alpha(x', x_n) | X' = x', X_n =x_n) =q(x' | x_n) \\alpha(x', x_n)\\] Since our outcomes are binary, $X_{n+1}$ either takes on $x’$ or $X_n$, we can directly construct our density function: . \\[\\text{Pr}(X_{n+1} | X_{n}) = w(x)f(x_{n+1} | x_n) + (1-w(x))1(X_{n+1} = X_n)\\] where $w(x)$ is: . \\[w(x_n) = \\int q(x_{n+1} | x_n) \\alpha(x_{n+1}, x_n)dx_{n+1}\\] and $f(x_{n+1} \\vert x_n)$ is: . \\[f(x_{n+1} | x_n) = \\frac{q(x_{n+1} | x_n) \\alpha(x_{n+1}, x_n)}{\\int q(x_{n+1}|x_n)\\alpha(x_{n+1} , x_n) dx_{n+1} }\\] We’ll now show the transition distribution satisfies the stationary distribution. We’d like to show the density kernel we just constructed converges to the target distribution: . \\[q(X_{n+1}) = \\int \\Pr(X_{n+1} | X_n)q(X_n)dX_{_n}\\] Here we assume our density is ergodic where detailed balance is a sufficient condition to show there exists a stationary distribution. Detailed Balance tells us the rate of transition given we start at $x’$ and move to $x_n$ must be equal to the rate of transition given we start at $x_n$ and move to $x’$. For the Metropolis Hastings, this looks like: . \\[q(x')\\Pr(X_{n+1} = x'| X_n = x_n) = q(x_n)\\Pr(X_{n+1} = x_n | X_{n} = x')\\] Claim: The Metropolis Hastings algorithm satisfies detailed balance. From the previous section we know the probability of transition is: . \\[\\Pr(X_{n+1} = x'| X_n = x_n) = p(x'|x_n)\\alpha(x',x_n) =p(x'|x_n) \\min \\{ 1, \\frac{q(x')p(x_n|x')}{q(x_n)p(x'|x_n)} \\}\\] We can expand the RHS further: . \\[=\\min\\{p(x'|x_n), \\frac{q(x')p(x_n|x')}{q(x_n)}\\}\\] If we multiply both sides by $q(x_n)$, we get: . \\[\\Pr(x'|x_n)q(x_n)= \\min ( q(x_n)p(x'|x_n),q(x')p(x_n|x'))\\] \\[\\Rightarrow \\Pr(x'|x_n)q(x_n) = \\Pr(x_n|x')q(x')\\] The Metropolis Hastings Algorithm satisfies detailed balance. Finally, we can integrate both sides w.r.t $x_n$ and find: . \\[q(x') = \\int \\Pr(x' |x_n)q(x_n)dx_n\\] \\[\\Rightarrow q(x_{n+1}) = \\int \\Pr(x_{n+1} |x_n)q(x_n)dx_n\\] ",
    "url": "/docs/Blog/Sampling/2025/05/18/Metropolis-Hastings#proof-of-metropolis-hastings-algorithm",
    
    "relUrl": "/docs/Blog/Sampling/2025/05/18/Metropolis-Hastings#proof-of-metropolis-hastings-algorithm"
  },"7": {
    "doc": "Metropolis-Hastings Algorithm",
    "title": "Metropolis-Hastings Algorithm",
    "content": " ",
    "url": "/docs/Blog/Sampling/2025/05/18/Metropolis-Hastings",
    
    "relUrl": "/docs/Blog/Sampling/2025/05/18/Metropolis-Hastings"
  },"8": {
    "doc": "Rejection Sampling",
    "title": "Rejection Sampling",
    "content": " ",
    "url": "/docs/Blog/Sampling/2025/05/19/rejection-sampling#rejection-sampling",
    
    "relUrl": "/docs/Blog/Sampling/2025/05/19/rejection-sampling#rejection-sampling"
  },"9": {
    "doc": "Rejection Sampling",
    "title": "Introduction",
    "content": "Rejection Sampling is an algorithm that provides us with an intuitive way to sample random variables from a target distribution, $q(x)$, that cannot be sampled from directly but whose function form is known. We do so by using a proposal distribution, $p(x)$, that can be sampled from directly. The rejection sampling algorithm requires samples drawn from $p(x)$ to be evaluated on a probability the sample can be assumed to have been drawn from $q(x)$. If the sample is not assumed to be drawn from $q(x)$, the sample is rejected and the process is repeated. The underlying acceptance of the sample drawn from $p(x)$ relies on the overlap between $p(x)$ and $q(x)$. If $p(x)$ and $q(x)$ are similar distributions then we say the two distributions have high overlap and samples drawn from either distribution could be said to have been drawn from the other. The opposite is true for distributions with low overlap. Rejection sampling provides us with an introductory understanding of overlap as we define the likelihood samples can replace each other with the constant $M$: . \\[M = \\sup_{x \\in \\Omega} \\frac{q(x)}{p(x)} &lt; \\infty\\] We note that $M \\geq 1$: . Proof: . Suppose $ M &lt; 1 $. Since $M$ is the supremum of $\\frac{q(x)}{p(x)}$, then for all $x$: \\(M \\geq \\frac{q(x)}{p(x)} \\implies M p(x) \\geq q(x).\\) . Integrating both sides: . \\[M \\int p(x) \\, dx \\geq \\int q(x) \\, dx.\\] Since $ p(x) $ and $ q(x) $ are p.d.f.s, $ \\int p(x) \\, dx = \\int q(x) \\, dx = 1 $. Thus, M \\geq 1, . which contradicts the assumption $ M &lt; 1 $. QED . Since $M \\geq 1$, we know the following must be true for $q(x)$: . | $q(x) \\geq p(x) \\space \\forall x \\in \\Omega$ | $p(x)$ and $q(x)$ share the same $\\Omega$ | . In rejection sampling, we define overlap with $M$ since $M$ serves as a measure of similarity between $p(x)$ and $q(x)$. If $M$ is very close to 1, $p(x)$ and $q(x)$ are quite similar. If $M$ is very close to 0, $p(x)$ and $q(x)$ are not similar. Note, a downside to rejection sampling is that $M$ must exist which heavily constrains the number of density functions we can apply rejection sampling sampling to. However, we know based on what was said above, the following figure shows us the relationship between $p(x)$ and $q(x)$. Once we’ve determined $M$, we can generate samples $X_1,X_2,…,X_n$ from $p(x)$ and apply the rejection sampling algorithm. We will show the accepted samples will then follow the target distribution $q(x)$. We can condense the above into the following algorithm: . 1.Draw a sample $X \\sim p(x)$ . 2.Draw a sample $u \\sim U[0,1]$ . 3.If $u &lt; \\frac{q(x)}{M*p(x)}$ then $X \\sim q$, else: Discard $X$ and $u$ . 4.Repeat . Here is an example of the algorithm implemented in Python: . import numpy as np import scipy def rejection_sampling(num_samples, M, prop_dist, target_dist): samples = [] for _ in range(num_samples): x = prop_dist.rvs() #Random variable from our proposed distribution u = scipy.stats.uniform.rvs() #Random variable from our uniform distribution #Ratio is the realized random variable evaluated at both the proposed and the target distributions ratio = target_dist.pdf(x) / (prop_dist.pdf(x)*M) if u &lt;= (ratio): # Accept-reject condition samples.append(x) return np.array(samples) . Example . Here we use $p \\sim \\text{Exp}(\\lambda = \\frac{1}{2})$ to target a standard exponential distribution: . Proof of Rejection Sampling . Our goal is to show that if we follow the rejection sample algorithm, the random variable we drew $X$ from $p(x)$, can be said $X \\sim q(x)$. Probability theory tells us that if $X \\sim q(x)$, the following are equivalent: . \\[\\Pr(X \\in A) = \\int_A q(x)\\text{dx} = Q(x)\\] Where $A$ is sample space of $q(x)$. This will be the idea we wish to prove. When we run the rejection sampling algorithm, there exists some probability we accept or reject the sample. This probability is random before the algorithm begins and based on the fact that we accept or reject, the outcome is binary. Whether or not the outcome occurs for every iteration of the algorithm is a random variable (r.v) that we call $Z$. We’ve defined the conditions when a sample $X$ is accepted rejected in the algorithm and it is based on the inequality: . $U &lt; \\frac{q(x)}{M*p(x)}$ . It follows that since M is the supremum of $\\frac{q(x)}{p(x)}$, if $M$ exists then $\\frac{q(x)}{M*p(x)}$ is bounded on the interval of $[0,1]$ for all $x$ in the support of $p(x)$ and $q(x)$. We can now assign the probability the event occurs to our new random variable $Z$ as: \\(Z \\sim \\text{Bernoulli}(\\frac{q(x)}{Mp(x)})\\) . Now that $Z$ is well defined, we turn our attention to the following: . \\[X \\space | \\space Z=1\\] We wish to answer: what is the distribution of $X$ after we’ve accepted the sample? We want to show that given an accepted sample, the sample comes from our target distribution $q(x)$. To show that we’ll need to prove: . \\[\\Pr(X \\in A | Z=1) = Q(x)\\] where $A$ is the sample space of $q(x)$. Using Bayes’ Theorem we can rewrite $\\Pr(X \\in A \\vert Z=1)$ as: . \\[\\Pr(X \\in A | Z=1) = \\frac{\\Pr(Z = 1 | X \\in A) \\cdot \\Pr(X \\in A)}{\\Pr(Z=1)}\\] Lets turn our attention to the numerator. Since we have a conditional probability, we can make the following observation: . \\[\\Pr(Z = 1 | X \\in A) = \\frac{\\Pr(Z=1 \\cap X \\in A)}{\\Pr(X \\in A)}\\] By multiplying both sides by $\\Pr(X \\in A)$ and plugging the right hand side into the numerator we arrive at: . \\[\\Pr(X \\in A | Z=1) = \\frac{\\Pr(Z=1 \\cap X \\in A)}{\\Pr(Z=1)}\\] Looking deeper into $\\Pr(Z=1 \\cap K \\in A)$, this is something we can evaluate: By the law of Total Probability: . \\[\\Pr(Z=1 \\cap K \\in A) = \\int_{A} (U &lt; \\frac{q(x)}{Mp(x)}) \\cdot p(x)\\text{dx} = \\iint_{0}^{1} (U &lt; \\frac{q(x)}{Mp(x)}) \\cdot p(x) \\text{dx}\\] \\[\\Rightarrow \\int_{-\\infty}^{\\infty} \\frac{q(x)}{Mp(x)}\\cdot p(x) \\text{dx} \\frac{1}{M} \\int_{-\\infty}^{\\infty}q(x)\\text{dx} = \\frac{1}{M} \\cdot Q(x)\\] Now we turn our focus to the denominator $\\Pr(Z=1)$. \\[\\Pr(Z=1) = \\int_{-\\infty}^{\\infty} 1(U &lt; \\frac{q(x)}{Mp(x)}) p(x) \\text{dx} = \\int_{-\\infty}^{\\infty} \\frac{q(x)}{Mp(x)}p(x) \\text{dx} = \\frac{1}{M} \\int_{-\\infty}^{\\infty} q(x)\\text{dx} = \\frac{1}{M}\\] Finishing up we arrive at out final result: . \\[\\Pr(X \\in A | Z=1) = \\frac{\\frac{1}{M} \\Pr(X \\in A)}{\\frac{1}{M}} = \\Pr(X \\in A) = Q(x)\\] Therefore, given we accept the random variable we sampled, we’ve shown $X \\sim q(x)$. ",
    "url": "/docs/Blog/Sampling/2025/05/19/rejection-sampling#introduction",
    
    "relUrl": "/docs/Blog/Sampling/2025/05/19/rejection-sampling#introduction"
  },"10": {
    "doc": "Rejection Sampling",
    "title": "Rejection Sampling",
    "content": " ",
    "url": "/docs/Blog/Sampling/2025/05/19/rejection-sampling",
    
    "relUrl": "/docs/Blog/Sampling/2025/05/19/rejection-sampling"
  },"11": {
    "doc": "Overlap Measure",
    "title": "Overlap",
    "content": "Throughout this analysis, there’s been mention to the notion of overlap between two distributions. The goal of this section is to define overlap and how we can leverage its interpretation in application over the commonly used p-value. ",
    "url": "/docs/Blog/Sampling/2025/05/27/overlap#overlap",
    
    "relUrl": "/docs/Blog/Sampling/2025/05/27/overlap#overlap"
  },"12": {
    "doc": "Overlap Measure",
    "title": "Overlap in Rejection Sampling",
    "content": "When describing the rejection sampling algorithm, we showed that we could define the probability a sample was accepted as $\\frac{1}{M}$. Here the constant M is defined as: \\(\\sup_{x \\in \\Omega}\\frac{q(x)}{p(x)}\\) Note that if $q(x) = p(x)$ then the sample would always be accepted. Similarly, if $q(x) = c p(x)$ where c is a constant, then the probability of acceptance would become $\\frac{1}{c}$. Of course, this definition leads to conclusion that if two distributions are more “overlapping”, then the probability of acceptance draws closer to 1 (Figure add). The challenge with rejection sampling is $M &lt; \\infty$. Often times, M being less than infinity is not the case removing both the interpretation of overlap and rendering rejection sampling useless. We’d like to find a way to remove this unnecessary constraint and find a definition of overlap that works for any $p(x)$, $q(x)$. ",
    "url": "/docs/Blog/Sampling/2025/05/27/overlap#overlap-in-rejection-sampling",
    
    "relUrl": "/docs/Blog/Sampling/2025/05/27/overlap#overlap-in-rejection-sampling"
  },"13": {
    "doc": "Overlap Measure",
    "title": "Overlap in Metropolis-Hastings",
    "content": "The second sampling algorithm we analyzed was the Metropolis-Hastings algorithm. One of the key properties of MH we derived was that it guarantees convergence to the stationary distribution under the condition of detailed balance. This provides an algorithm that works for any $p(x), q(x)$ regardless of how slow that convergence may be. This provides a significant advantage over Rejection Sampling since we can define overlap for any $p(x)$ and $q(x)$. However, the challenge now is defining overlap in the MH algorithm. Claim: The integral $\\int \\int \\alpha(x’,x)p(x)q(x’)\\text{d}x\\text{d}x’$ gives us a measure of overlap of the MH algorithm. We’ll define Z to be a Bernoulli random variable indicating whether or not our sample was rejected and we’ll start with the following set up: . Suppose a target distribution $q(x)$ and a proposal distribution $p(x)$. Let $X \\sim q(x)$ and $Y \\sim p(y)$. We’d like to know the probability X can replace Y after the test: $u &lt; \\alpha(X, Y)$. Define $z$ to be a r.v st: \\(X' = \\begin{cases} X \\text{ with probability } \\alpha(X, Y) \\\\ Y \\text{ with probability } 1-\\alpha(X, Y) \\end{cases}\\) . We’d like show $X’ \\sim q(x)$. Clearly if we reject our sample $X$, $X’ \\sim q$ since $X’ = Y$. If we accept the sample, then we were saying $X$ can replace $Y$. We can make the following observation of the probability of replacement: . \\[\\Pr(Z=1 \\cap X' \\in A | X) = \\int \\int \\int_A 1(U &lt; \\alpha(X, Y)) q(x)p(y)\\text{d}u\\text{d}x\\text{d}y\\] \\[= \\int \\int \\alpha(x,y)q(x)p(y)\\text{d}x\\text{d}y\\] Where $A$ is the sample space of $q(x)$. This is our overlap measure, we’ll denote it with $r$. \\[r = \\int \\int \\alpha(x,y)q(x)p(y)\\text{d}x\\text{d}y\\] Since r is a well defined probability, $r \\in [0,1]$ and has the following interpretation: . | If r is close to zero, that indicates the target and proposal are distinct distributions since there is a low replacement probability. | If r is close to one, then the proposal and distinct are similar distributions. | Computing r directly may not be always possible, the probability must be estimated using Monte Carlo methods. | . In conclusion, since the Metropolis Hastings converges to the target distribution for any proposal distribution, the overlap measure for the Metropolis Hastings works for any two $p(x)$ and $q(x)$. This allows us to determine the similarity between samples coming from two different distributions by determining how likely one sample is to replace the other. ",
    "url": "/docs/Blog/Sampling/2025/05/27/overlap#overlap-in-metropolis-hastings",
    
    "relUrl": "/docs/Blog/Sampling/2025/05/27/overlap#overlap-in-metropolis-hastings"
  },"14": {
    "doc": "Overlap Measure",
    "title": "Similarity measures: p-value vs Overlap",
    "content": "The p-value is the probability a test statistic is at least as extreme as the actual observed value, given that a null hypothesis is true. One common application of the p-value is to test the differences between two populations (X and Y) by using the means from the observed samples and constructing the following null hypothesis: . \\[H_0 \\colon \\ \\mu_X - \\mu_Y = 0 \\quad H_1 \\colon \\ \\mu_X - \\mu_Y \\neq 0\\] We arrive at what is referred to as the two sample t-test. By rejecting the null hypothesis, we accept strong evidence to suggest the means are not the same, indicating a difference between the two populations. The threshold for p-value (commonly referred to as $\\alpha$) is selected based on a widely accepted consensus, typically .05. However, given the goal is to measure differences between two populations, the threshold we set for the p-value is uninformative about the difference between the two populations. Instead of the p-value, we’d like to focus on $r$ and its interpretation as a measure of replacement between two populations to describe similarity between distinct distributions. Example: p-value vs. Overlap . For this example, we’ll consider two populations: . \\[X_1, X_2, ..., X_N \\text{ i.i.d from N(0,1)}\\] and . \\[Y_1, Y_2, ..., Y_N \\text{ i.i.d from N(}\\mu \\text{,1)}\\] where $\\mu \\in [0,2]$. We’d like to compare the similarity of the two distributions using both a two sample mean test and $r$ and highlight the difference between the two measures as $\\mu$ grows larger and the distributions grow farther apart. Since $r$ cannot be directly computed, it must be estimated using Monte Carlo methods. We’ll estimate $r$ using the following code: . import pandas as pd import scipy import numpy as np np.random.seed(42) # Generate data means = np.arange(0, 200) / 100 # For reproducibility x = scipy.stats.norm.rvs(size=50) y = scipy.stats.norm.rvs(size=50) fx_hat = scipy.stats.gaussian_kde(x) # Fit KDE for x (fixed) fx_s = fx_hat.resample(1000).flatten() # Pre-sample overlaps = [] p_values = [] for mu in means: y_mu = y + mu fy_hat = scipy.stats.gaussian_kde(y_mu) # Fit KDE for shifted y fy_s = fy_hat.resample(1000).flatten() #Drawing 1000 samples from the fy hat # Two-sample t-test (two-sided by default) tstat, p_val = scipy.stats.ttest_ind(x, y_mu, equal_var=False) # Welch's t-test p_values.append(p_val) # Monte Carlo overlap estimation eps = 1e-10 # Small constant to avoid division by zero numerator = fx_hat(fy_s) * fy_hat(fx_s) denom = fx_hat(fx_s) * fy_hat(fy_s) alpha = np.minimum(1, (numerator / denom)) overlaps.append(np.mean(alpha)) df = pd.DataFrame({'Overlap': overlaps, 'p-value': p_values}, index=means) #Store results . Results . We obtain the following result: . From this example we see as the p-value dips below .05 and we begin to reject the null hypothesis, the overlap remains high at roughly .75 probability a sample from $\\text{N(0,1)}$ could replace a sample from $\\text{N(}\\mu,1)$. From this example, we see the additional information we gain from using the overlap measure could be far more valuable to the researcher since three-fourth’s of samples from one group could replace those of the other group. ",
    "url": "/docs/Blog/Sampling/2025/05/27/overlap#similarity-measures-p-value-vs-overlap",
    
    "relUrl": "/docs/Blog/Sampling/2025/05/27/overlap#similarity-measures-p-value-vs-overlap"
  },"15": {
    "doc": "Overlap Measure",
    "title": "Overlap Measure",
    "content": " ",
    "url": "/docs/Blog/Sampling/2025/05/27/overlap",
    
    "relUrl": "/docs/Blog/Sampling/2025/05/27/overlap"
  },"16": {
    "doc": "Sampling",
    "title": "Sampling",
    "content": " ",
    "url": "/docs/Blog/Sampling/2025/05/28/sampling",
    
    "relUrl": "/docs/Blog/Sampling/2025/05/28/sampling"
  },"17": {
    "doc": "Portfolio Website Updates",
    "title": "The Problem:",
    "content": "About a month ago, I graduated from college. I didn’t have many job opportunities waiting for me after I graduated. This wasn’t a struggle I was unaccustomed to; I even struggled to gain any attention for an internship during my time as an undergrad. At the time, I didn’t understand why. I was a pretty good student; my projects were interesting but not groundbreaking; I was never a part of any club during school, but I kept myself so busy with my studies that I kind of put that stuff to the side. In retrospect, that was and is my biggest regret as an undergrad. Still, I knew that if I wanted a job (especially in data science) I needed, for the first time in my life, to put myself out there and show what makes me different instead of believing that I am different. ",
    "url": "/Portfolio/2025/06/10/portfolio-website-blog#the-problem",
    
    "relUrl": "/Portfolio/2025/06/10/portfolio-website-blog#the-problem"
  },"18": {
    "doc": "Portfolio Website Updates",
    "title": "The Idea:",
    "content": "That’s when I had the idea of building a portfolio website. While it may not be a unique idea, it’s still a place that is all about me, built by me, for me. Wellllll, there’s only one problem: I don’t know the first thing about HTML, CSS, or JavaScript. Also, hosting a website costs money, and I’m not sure I can justify the investment right now. Luckily for me, after doing some research, all I can say is: Thank God for the year 2025. ",
    "url": "/Portfolio/2025/06/10/portfolio-website-blog#the-idea",
    
    "relUrl": "/Portfolio/2025/06/10/portfolio-website-blog#the-idea"
  },"19": {
    "doc": "Portfolio Website Updates",
    "title": "The Execution:",
    "content": "Learning HTML was never the problem; yes, it’s a significant time investment, but as a 22 year old fresh grad, I have nothing but time. But as a 22 year old fresh grad, what money did I have to buy a domain and host a website? Luckily, GitHub hosts what are called GitHub Pages, which can host static websites for free, perfect for developing your own portfolio website. Seeing as the money problem was solved, it was time to learn HTML and CSS. ",
    "url": "/Portfolio/2025/06/10/portfolio-website-blog#the-execution",
    
    "relUrl": "/Portfolio/2025/06/10/portfolio-website-blog#the-execution"
  },"20": {
    "doc": "Portfolio Website Updates",
    "title": "Version 1: A Blast From the Past",
    "content": "One benefit of using Github Pages to host a website is access to Git’s version control. Using version control, we can look at previous versions of what the home page is and easily see how far I’ve come. My original design for the website was very simple: Go to the domain, have a homepage, click on a portfolio tab, have an about page, a contact page, and call it a day. Using DeepSeek, I learned some of the basics of building an HTML website with some CSS elements. I had spent the whole semester on a write up with my professor that I found really interesting which was about the Metropolis-Hastings algorithm (which you can read here if you’re interested wink wink) so I knew I also had the content I wanted to post. With that in mind, I created version one: . This website was okay! For 2007. Seriously though, I could see the room for improvement, and I was happy with the work that was left to be done. ",
    "url": "/Portfolio/2025/06/10/portfolio-website-blog#version-1-a-blast-from-the-past",
    
    "relUrl": "/Portfolio/2025/06/10/portfolio-website-blog#version-1-a-blast-from-the-past"
  },"21": {
    "doc": "Portfolio Website Updates",
    "title": "Version 2: Boxes, Boxes, and More Boxes",
    "content": "V2 I would call my box era. Everything neeeded a box. If it it was text outside of the hero section, it better be in container. Here I learned how to place images in my boxes, add some links to outside my website and render some LaTeX that my content needed to include. However I found the content to be a little too seperated. I could reach my about, blog, and content, but it felt like for the little content that it contained, they made for underwhelming individual pages. Either way, in about a week I went from 2007 to 2010. (Honestly an insult to the websites at that time, lol) . ",
    "url": "/Portfolio/2025/06/10/portfolio-website-blog#version-2-boxes-boxes-and-more-boxes",
    
    "relUrl": "/Portfolio/2025/06/10/portfolio-website-blog#version-2-boxes-boxes-and-more-boxes"
  },"22": {
    "doc": "Portfolio Website Updates",
    "title": "Version 3: Too Many Pages!",
    "content": "After moving everything to the index page, I was focused on getting my md pages that needed LaTeX to render properly. I also didn’t want these pages to be boring. They were loading on white pages that were filled with text and some images, but I really hated this. Luckily, GitHub Pages allows you to import themes into your website, however, these themes overwrite everything and assume you’re building your whole website on top of these themes. I didn’t want that; I still wanted to keep the structure of my page and introduce the theme when someone clicked on the link. The theme, Just the Docs, would look nice since it’s similar to what online math textbooks use and the pages I want the theme to apply to are math heavy. Also, I force myself to use live preview here since I was originally pushing and waiting for the website to update to see my changes (CRAZY LOL). ",
    "url": "/Portfolio/2025/06/10/portfolio-website-blog#version-3-too-many-pages",
    
    "relUrl": "/Portfolio/2025/06/10/portfolio-website-blog#version-3-too-many-pages"
  },"23": {
    "doc": "Portfolio Website Updates",
    "title": "Version 4: Overhaul",
    "content": "I finally got everything to work properly. YAY! I should be done and ready to present my website, right? Right? Well…. not quite. I wake up one morning and realize, I hate everything about this website. It’s hard to scale, it looks out of date, and it doesn’t render properly on mobile. So, like any rational person would decide, I delete everything and start from scratch. This time I look for inspiration from other creators on Reddit and I find different layouts I really love. This time, I decide to use TailwindCSS as a modern framework for the page and start from a mobile first approach. And that leads us to today June 6th, 2025 where I’m currently updating my page and slowly adding back all the content from v3! . ",
    "url": "/Portfolio/2025/06/10/portfolio-website-blog#version-4-overhaul",
    
    "relUrl": "/Portfolio/2025/06/10/portfolio-website-blog#version-4-overhaul"
  },"24": {
    "doc": "Portfolio Website Updates",
    "title": "Portfolio Website Updates",
    "content": " ",
    "url": "/Portfolio/2025/06/10/portfolio-website-blog",
    
    "relUrl": "/Portfolio/2025/06/10/portfolio-website-blog"
  },"25": {
    "doc": "Application - Overlap Measure and RAND HIE (WIP)",
    "title": "Introduction",
    "content": "The overlap measure provides us a way to conceretly measure changes between a population before and after a treatment. What makes the overlap measure so powerful is that it is a method of comparison between populations without the use of a p-value that also gives a value of the percent of individuals who change after having a treatment applied. Overlap, therefore, does not suffer from the same downsides as the p-value, mainly Overlap is not: . | Vulnerable to p-hacking | A probability that can be proven to be false | . While I do not believe the overlap measure should be a direct replacement of the p-value, nor do I believe that was the purpose of the incepetion of the overlap measure; by removing the p-value from our statisical analysis we force ourselves to recreate the strength of the validity “statistically significant”results have with a far more data driven approach. The overlap merely carries with it a numerical ouput of the distirbutional similiarity between the before and after treatment distributions. The goal of this article is thus a practical application of the overlap measure and discovering insights into datasets where the p-value dound results that were not statistically significant but individuals who underwent a treatment did still behave differently than they did before the treatment. ",
    "url": "/docs/Portfolio/Overlap_RANDHIE#introduction",
    
    "relUrl": "/docs/Portfolio/Overlap_RANDHIE#introduction"
  },"26": {
    "doc": "Application - Overlap Measure and RAND HIE (WIP)",
    "title": "Introduction to RAND HIE",
    "content": " ",
    "url": "/docs/Portfolio/Overlap_RANDHIE#introduction-to-rand-hie",
    
    "relUrl": "/docs/Portfolio/Overlap_RANDHIE#introduction-to-rand-hie"
  },"27": {
    "doc": "Application - Overlap Measure and RAND HIE (WIP)",
    "title": "Application - Overlap Measure and RAND HIE (WIP)",
    "content": "Prerequisite: Overlap Measure . ",
    "url": "/docs/Portfolio/Overlap_RANDHIE",
    
    "relUrl": "/docs/Portfolio/Overlap_RANDHIE"
  },"28": {
    "doc": "FinBERT 2",
    "title": "Introduction",
    "content": "I was asked by a friend who has been working on building his expertise in the world of quantitative trading to build a sentiment analysis model to quickly quantify the sentiment of recent, relevant financial news articles of specific publicly traded companies as a component for a portfolio he was looking to build and manage. I agreed and began to build an end to end system that was capable of the following: . | Injest news articles from major American news sources along with news aggregators for sentiment on general, daily, stock market sentiment | Store data obtained from web crawling, model training, and model predictions | Store the trained Large Language Model for quick prediction, one off prediction | . Here’s the system I ultimately developed: . The construction of the system will be seperated into three parts including: . Model Building . [Scraper Development] . [Database and pipeline Development] . ",
    "url": "/docs/Portfolio/FinBERT_2#introduction",
    
    "relUrl": "/docs/Portfolio/FinBERT_2#introduction"
  },"29": {
    "doc": "FinBERT 2",
    "title": "FinBERT 2",
    "content": " ",
    "url": "/docs/Portfolio/FinBERT_2",
    
    "relUrl": "/docs/Portfolio/FinBERT_2"
  },"30": {
    "doc": "FinBERT 2 - Model Building",
    "title": "Introduction to Sentiment Analysis",
    "content": "Sentiment analysis is the popular classification technique of determining attidues around a subject, entity, or event from natural language. The method and techniques of implementing sentiment analysis are long and well-documented from “simple” and inuitive models such as logistic regression and Naive Bayes Classifier and training models using a collection of vocabulary words (Bag of Words) to highly sophisticated and state of the art large language/reasoning models such as GPT-4, o4, BERT, Claude Opus 4 trained on large corpus of text throught the use of embeding layers that preserve word order, sentiment analysis seems to be a persistent and well researched topic surrounding these forementioned methods of prediction. Sentiment Analysis Using BERT . Improvements in the sophistication of models with the rise of attention based architecture have significantly improved performance of sentiment analysis over previous models such as recurrent neural networks or convolution neural networks due to the positional embeddings the model learns through pre-training and transformers ability to process whole sentences rather than word for word. The downside to the transformer model is its use of massive datasets and heavy computation costs. However, we overcome the limitation of pretraining BERT on the standard Wikipedia and Book corpora by using the pretrained BERT from the Huggingface library. Further Pretraining = Improved Results? . Text in financial data is notoriously tricky to detect sentiment due to the unique vocabulary and the lack of proper and labeled data make applying sentiment analysis difficult. This is where FinBERT comes in. FinBERT is a variation of BERT desinged specifically for application in the financial domain by using a method known as “further pre-training” which is training a BERT model on domain relevant corpa using the same training methods (masked language modeling and next sentence prediction) done during the training on the Wikipedia and BookCourpa corpora. The authors of FinBERT decided to use Reuters TRC2 dataset and then filtering down to financial news articles for the pretraining of BERT; the idea of the pretraining is that it allows BERT to adjust its positional embeddings before it is fine-tuned on domain-specific dataset. After pretraining, FinBERT was then fine-tuned on the Financial Phrasebank dataset where it proved noticeable improvements over a standard BERT, ELmO, and (I forgot the last one). The result of this further pretraining demostrated the effectiveness and possibility of making better, domain-specific models for the purpose of sentiment analysis. ",
    "url": "/docs/Portfolio/FinBERT_2/model_building#introduction-to-sentiment-analysis",
    
    "relUrl": "/docs/Portfolio/FinBERT_2/model_building#introduction-to-sentiment-analysis"
  },"31": {
    "doc": "FinBERT 2 - Model Building",
    "title": "Why FinBERT 2?",
    "content": "The original FinBERT model was made in 2019. Since then with a substantial rise of retail investors [link here], the COVID-19 pandemic, and the impact of Artifical Intelligence, rising interest rates have made both changes in the way we communicate and the way markets, particularly stock markets, operate in higher volatility enviroment. It is my personal belief that the change in enviroment should be reflected in the data we use to train our LLMs, this to me, is particularly important when it comes to training LLMs on domain specific tasks. For that reason, the data we collect and use to train FinBERT 2 should reflect my sentiment. Ideally, we want a LLM that is knowledgeable on financial vocabulary and news but is also an excellent room reader and can understand the anger/frustration/skepticism traders may have towards a stock. ",
    "url": "/docs/Portfolio/FinBERT_2/model_building#why-finbert-2",
    
    "relUrl": "/docs/Portfolio/FinBERT_2/model_building#why-finbert-2"
  },"32": {
    "doc": "FinBERT 2 - Model Building",
    "title": "Collecting Datasets",
    "content": " ",
    "url": "/docs/Portfolio/FinBERT_2/model_building#collecting-datasets",
    
    "relUrl": "/docs/Portfolio/FinBERT_2/model_building#collecting-datasets"
  },"33": {
    "doc": "FinBERT 2 - Model Building",
    "title": "Model Training and Data Colletion",
    "content": "For the pretraining, we’ll be using Huggingface extensively as it offers a variety of benefits when it comes to training LLMs. Using HuggingFace gives us access to a variety of large datasets perfect for training LLMs and are easy to access using the HuggingFace API in Python. HuggingFace also allows for me store up to 100gb that can be used to store tokenized datasets so they don’t have to be loaded in locally. Most importantly, as noted earlier, HuggingFace provides easy access to the BERT model that is already pretrained on the Wikipedia and BookCorpus corpora along with the functions necessary to carry out the further pretraining. ",
    "url": "/docs/Portfolio/FinBERT_2/model_building#model-training-and-data-colletion",
    
    "relUrl": "/docs/Portfolio/FinBERT_2/model_building#model-training-and-data-colletion"
  },"34": {
    "doc": "FinBERT 2 - Model Building",
    "title": "Data Accessing",
    "content": "To access the Huggingface datasets, we’ll be using PySpark over popular alternatives such as Pandas. The reason for this is that if we wanted to increase the number of datasets to manage, PySpark would easily be able to handle the processing and loading required by the data. ",
    "url": "/docs/Portfolio/FinBERT_2/model_building#data-accessing",
    
    "relUrl": "/docs/Portfolio/FinBERT_2/model_building#data-accessing"
  },"35": {
    "doc": "FinBERT 2 - Model Building",
    "title": "Data Collection",
    "content": "For further pretraining, the two datasets we’ll look to use are the Reuteurs Financial Dataset that records Reuteurs Financial news artciles from 2006-2013 and this corpora of Financial News Articles from seemingly 2017-2018. Finally, we’ll use the FinTwit dataset. ",
    "url": "/docs/Portfolio/FinBERT_2/model_building#data-collection",
    
    "relUrl": "/docs/Portfolio/FinBERT_2/model_building#data-collection"
  },"36": {
    "doc": "FinBERT 2 - Model Building",
    "title": "FinBERT 2 - Model Building",
    "content": " ",
    "url": "/docs/Portfolio/FinBERT_2/model_building",
    
    "relUrl": "/docs/Portfolio/FinBERT_2/model_building"
  }
}
